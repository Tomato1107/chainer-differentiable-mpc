{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imitation Learning \n",
    "\n",
    "Learn {A, B} (dynamics) from imitation loss which is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "Loss ={E}_{\\text{x_init}} [\\|\\tau(x_\\text{init}; \\theta)- \\tau(x_\\text{init};\\hat{\\theta})|_2^2]\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seed = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i19_arahata/.local/share/virtualenvs/chainer-mpc-dl9ARfgC/lib/python3.7/site-packages/chainer/_environment_check.py:41: UserWarning: Accelerate has been detected as a NumPy backend library.\n",
      "vecLib, which is a part of Accelerate, is known not to work correctly with Chainer.\n",
      "We recommend using other BLAS libraries such as OpenBLAS.\n",
      "For details of the issue, please see\n",
      "https://docs.chainer.org/en/stable/tips.html#mnist-example-does-not-converge-in-cpu-mode-on-mac-os-x.\n",
      "\n",
      "Please be aware that Mac OS X is not an officially supported OS.\n",
      "\n",
      "  ''')  # NOQA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport matplotlib.pyplot as plt\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cost はすでに求められていて部分的にBack Propagationをする\n",
    "import chainer\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../lqr\")\n",
    "from lqr_recursion import LqrRecursion\n",
    "from differentiable_lqr import  DiffLqr, LqrNet\n",
    "from chainer import functions as F\n",
    "import chainer.computational_graph as c\n",
    "from util import expand_time_batch\n",
    "import os\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 5\n",
    "n_state = 3\n",
    "n_ctrl = 1\n",
    "n_sc = n_ctrl + n_state\n",
    "n_batch = 128\n",
    "dtype = np.float64\n",
    "expert_seed = 42\n",
    "np.random.seed(expert_seed)\n",
    "alpha = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = dict(\n",
    "    Q = chainer.Variable(np.eye(n_sc)), #Cost\n",
    "    p = chainer.Variable(np.random.randn(n_sc)), # cost (little c)\n",
    "    A = chainer.Variable(np.eye(n_state) + alpha * np.random.randn(n_state, n_state)), # F left side\n",
    "    B = chainer.Variable(np.random.randn(n_state, n_ctrl))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ab_cat = F.concat((exp['A'], exp['B']), axis=1)\n",
    "exp_large_f = expand_time_batch(exp_ab_cat, T-1, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp['F'] = exp_large_f\n",
    "exp['f'] = None\n",
    "exp_C = expand_time_batch(exp['Q'], T, n_batch)\n",
    "exp['C'] = exp_C\n",
    "exp['c'] = expand_time_batch(exp['p'], T, n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_loss(x_init):\n",
    "    expert = LqrRecursion(x_init, exp['C'], exp['c'], exp['F'], exp['f'], T, n_state, n_ctrl)\n",
    "    x_true, u_true = expert.solve_recursion()    \n",
    "    x_pred, u_pred = net((x_init, exp['C'], exp['c'], exp['f']))\n",
    "    # print(u_pred.dtype)\n",
    "    '''\n",
    "    g = c.build_computational_graph((x_pred), remove_split=True)\n",
    "    print(g.nodes)\n",
    "    for i in range(len(g.nodes)):\n",
    "        print(g.nodes[i])\n",
    "        print(g.nodes[i].label)\n",
    "    with open('grapht.dot', 'w') as o:\n",
    "        tmp = g.dump()\n",
    "        o.write(tmp)\n",
    "    '''\n",
    "    trajectory_loss = F.mean((u_true - u_pred)**2) + F.mean((x_true - x_pred)**2)\n",
    "    \n",
    "    return trajectory_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = chainer.optimizers.RMSprop(lr=1e-2)\n",
    "net = LqrNet(T, n_batch, n_state, n_ctrl, train_seed)\n",
    "opt.setup(net)\n",
    "fname =str(train_seed)+'_losses.csv'\n",
    "loss_f = open(fname, 'w')\n",
    "loss_f.write('im_loss,mse\\n')\n",
    "loss_f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 0.661925 dyanmics loss  4.774785\n",
      "iteration 10 0.294314 dyanmics loss  4.722322\n",
      "iteration 20 0.229643 dyanmics loss  4.779115\n",
      "iteration 30 0.176507 dyanmics loss  4.801983\n",
      "iteration 40 0.161523 dyanmics loss  4.819201\n",
      "iteration 50 0.219494 dyanmics loss  4.833848\n",
      "iteration 60 0.148188 dyanmics loss  4.845135\n",
      "iteration 70 0.134515 dyanmics loss  4.835713\n",
      "iteration 80 0.164870 dyanmics loss  4.823391\n",
      "iteration 90 0.197836 dyanmics loss  4.798079\n",
      "iteration 100 0.133565 dyanmics loss  4.785647\n",
      "iteration 110 0.146801 dyanmics loss  4.759894\n",
      "iteration 120 0.146065 dyanmics loss  4.724303\n",
      "iteration 130 0.166107 dyanmics loss  4.678963\n",
      "iteration 140 0.145697 dyanmics loss  4.630056\n",
      "iteration 150 0.146848 dyanmics loss  4.585837\n",
      "iteration 160 0.155886 dyanmics loss  4.535748\n",
      "iteration 170 0.146954 dyanmics loss  4.473944\n",
      "iteration 180 0.140506 dyanmics loss  4.407619\n",
      "iteration 190 0.137744 dyanmics loss  4.346956\n"
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    net.cleargrads()\n",
    "    x_init = chainer.Variable(np.random.randn(n_batch, n_state))\n",
    "    loss = get_loss(x_init)\n",
    "    loss.backward()\n",
    "    opt.update()\n",
    "    model_loss = F.mean((net.A - exp['A'])**2) + F.mean((net.B - exp['B'])**2)\n",
    "    loss_f.write('{},{}\\n'.format(loss.data, model_loss.data))\n",
    "    loss_f.flush()\n",
    "    plot_interval = 10\n",
    "    if i % plot_interval == 0:\n",
    "        print(\"iteration\", i,  \"{0:04f}\".format(loss.data), \"dyanmics loss \", \"{0:04f}\".format(model_loss.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.4",
    "jupytext_version": "1.2.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
